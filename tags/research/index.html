<!DOCTYPE html>
<html lang="en" itemscope itemtype="http://schema.org/WebPage">
  <head>
    

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0">

  <title>Research - Kai Kunze</title><script type="application/ld+json">
{
    "@context": "http://schema.org",
    "@type": "WebSite",
    "name": "Kai Kunze",
    
    "url": "https:\/\/kaikunze.de\/"
}
</script><script type="application/ld+json">
{
  "@context": "http://schema.org",
  "@type": "Organization",
  "name": "",
  "url": "https:\/\/kaikunze.de\/"
  
  
  
  
}
</script>

<meta property="og:title" content="Research" />
<meta property="og:image" content="https://kaikunze.de/img/avatar-icon-1.png" />
<meta property="og:url" content="https://kaikunze.de/tags/research/" />
<meta property="og:type" content="website" />
<meta property="og:site_name" content="Kai Kunze" />

  <meta name="twitter:title" content="Research" />
  <meta name="twitter:image" content="https://kaikunze.de/img/avatar-icon-1.png" />
  <meta name="twitter:card" content="summary" />
  <link href='https://kaikunze.de/img/favicon.ico' rel='icon' type='image/x-icon'/>
  <meta name="generator" content="Hugo 0.147.8">
  <link rel="alternate" href="https://kaikunze.de/index.xml" type="application/rss+xml" title="Kai Kunze"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css" integrity="sha384-9eLZqc9ds8eNjO3TmqPeYcDj8n+Qfa4nuSiGYa6DjLNcv9BtN69ZIulL9+8CqC9Y" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.5.0/css/all.css" integrity="sha384-B4dIYHKNBt8Bc12p+WXckhzcICo0wtJAoU8YZTY5qE0Id1GSseTk6S+L3BlXeVIU" crossorigin="anonymous">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous"><link rel="stylesheet" href="https://kaikunze.de/css/main.css" /><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic" />
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800" />
  <link rel="stylesheet" href="https://kaikunze.de/css/highlight.min.css" /><link rel="stylesheet" href="https://kaikunze.de/css/codeblock.css" /><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/photoswipe.min.css" integrity="sha384-h/L2W9KefUClHWaty3SLE5F/qvc4djlyR4qY3NUV5HGQBBW7stbcfff1+I/vmsHh" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/default-skin/default-skin.min.css" integrity="sha384-iD0dNku6PYSIQLyfTOpB06F2KCZJAKLOThS5HRe8b3ibhdEQ6eKsFf/EeFxdOt5R" crossorigin="anonymous">


  </head>
  <body>
    <nav class="navbar navbar-default navbar-fixed-top navbar-custom">
  <div class="container-fluid">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#main-navbar">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="https://kaikunze.de/">Kai Kunze</a>
    </div>

    <div class="collapse navbar-collapse" id="main-navbar">
      <ul class="nav navbar-nav navbar-right">
        
          
            <li>
              <a title="writing" href="/">writing</a>
            </li>
          
        
          
            <li>
              <a title="projects" href="/projects/">projects</a>
            </li>
          
        
          
            <li>
              <a title="papers" href="/publications/">papers</a>
            </li>
          
        
          
            <li>
              <a title="about" href="/about/">about</a>
            </li>
          
        

        

        
      </ul>
    </div>

    
      <div class="avatar-container">
        <div class="avatar-img-border">
          <a title="Kai Kunze" href="https://kaikunze.de/">
            <img class="avatar-img" src="https://kaikunze.de/img/avatar-icon-1.png" alt="Kai Kunze" />
          </a>
        </div>
      </div>
    

  </div>
</nav>




    


<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

<div class="pswp__bg"></div>

<div class="pswp__scroll-wrap">
    
    <div class="pswp__container">
      <div class="pswp__item"></div>
      <div class="pswp__item"></div>
      <div class="pswp__item"></div>
    </div>
    
    <div class="pswp__ui pswp__ui--hidden">
    <div class="pswp__top-bar">
      
      <div class="pswp__counter"></div>
      <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
      <button class="pswp__button pswp__button--share" title="Share"></button>
      <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
      <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>
      
      
      <div class="pswp__preloader">
        <div class="pswp__preloader__icn">
          <div class="pswp__preloader__cut">
            <div class="pswp__preloader__donut"></div>
          </div>
        </div>
      </div>
    </div>
    <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
      <div class="pswp__share-tooltip"></div>
    </div>
    <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
    </button>
    <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
    </button>
    <div class="pswp__caption">
      <div class="pswp__caption__center"></div>
    </div>
    </div>
    </div>
</div>


  
  
  







 
        <div id = "pagefloat"> </div>        
        <div id="nsplash" >
        <iframe id="nsplash_iframe"> </iframe>
        <div id="splash_title">
                   <h1>Research</h1>
         </div>
              
              
        </div>

        <div class="intro-header no-img">
      <div class="container">
        <div class="row">
          <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
            <div class="tags-heading">
                           
            </div>
          </div>
        </div>
      </div>
    </div>



    
  <div class="container" role="main">
    <div class="row">
      <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
        
        <div class="posts-list">
          
            <article class="post-preview">
    <a href="https://kaikunze.de/2013/09/15/ubicom-iswc-impressions/">
        <h2 class="post-title">Ubicomp ISWC Impressions</h2>
        
        
        
    </a>

    <p class="post-meta">
        <span class="post-meta">
  
  
  <i class="fas fa-calendar"></i>&nbsp;
  
  
    &nbsp;|&nbsp;<i class="fas fa-clock"></i>&nbsp;2&nbsp;minutes
  
  
    &nbsp;|&nbsp;<i class="fas fa-book"></i>&nbsp;314&nbsp;words
  
  
  
</span>


    </p>
    <div class="post-entry">
        
        <p>Usually, I&rsquo;m not such a big fan of conference openings,
yet Friedemann Mattern provided a great intro giving
an overview about the origins of Pervasive and Ubicom
mentioning all important people and showing nice vintage
pictures from Hans Gellersen, Alois Ferscha,  Marc Langheinrich, Albrecht Schmidt, Kristof Van Laerhoven etc.</p>
<p>Deeply impressed by the organization, social and general
talk quality, I was a bit sceptical before the merger
of Pervasive / Ubicom and collocating ISWC, yet it was
completely unfounded.</p>
<p>We got some great feedback for Kazuma&rsquo;s and Shoya&rsquo;s demos.
They both did a great job introducing their work about:</p>
<ul>
<li><a href="/papers/kunze2013my.pdf">My Reading Life – Towards Utilizing Eyetracking on Unmodified Tablets and Phones</a></li>
<li><a href="/papers/kunze2013annotate.pdf">Annotate Me – Supporting Active Reading using Real-Time Document Image Retrieval On Mobile Devices</a></li>
</ul>
<p>We got also a lof of interest and feedback
to Andreas Bulling&rsquo;s and my work about recognizing
document types using only eye gaze.
By the way, below are the talk slides and the abstract of
the paper.
##ISWC Talk Slides##</p>
<script class="speakerdeck-embed" data-id="a0f70c60fdc20130468e062acf92b5fe" data-ratio="1.33333333333333" src="//speakerdeck.com/assets/embed.js">  </script>
<p>##Abstract##
Reading is a ubiquitous activity that many people even per- form in transit, such as while on the bus or while walking. Tracking reading enables us to gain more insights about ex- pertise level and potential knowledge of users – towards a reading log tracking and improve knowledge acquisition. As a first step towards this vision, in this work we investigate whether different document types can be automatically de- tected from visual behaviour recorded using a mobile eye tracker. We present an initial recognition approach that com- bines special purpose eye movement features as well as ma- chine learning for document type detection. We evaluate our approach in a user study with eight participants and five Japanese document types and achieve a recognition perfor- mance of 74% using user-independent training.</p>
<p>Full paper link:
<a href="/papers/2013Kunze-5.pdf">I know what you are reading – Recognition of Document Types Using Mobile Eye Tracking</a></p>

        
    </div>

    
    <div class="blog-tags">
        
        <a href="https://kaikunze.de//tags/conference/">conference</a>&nbsp;
        
        <a href="https://kaikunze.de//tags/research/">research</a>&nbsp;
        
        <a href="https://kaikunze.de//tags/ubicomp/">ubicomp</a>&nbsp;
        
        <a href="https://kaikunze.de//tags/iswc/">iswc</a>&nbsp;
        
    </div>
    

</article>
          
            <article class="post-preview">
    <a href="https://kaikunze.de/2013/09/06/excited-about-ubicomp-and-iswc/">
        <h2 class="post-title">Excited about Ubicomp and ISWC</h2>
        
        
        
    </a>

    <p class="post-meta">
        <span class="post-meta">
  
  
  <i class="fas fa-calendar"></i>&nbsp;
  
  
    &nbsp;|&nbsp;<i class="fas fa-clock"></i>&nbsp;2&nbsp;minutes
  
  
    &nbsp;|&nbsp;<i class="fas fa-book"></i>&nbsp;240&nbsp;words
  
  
  
</span>


    </p>
    <div class="post-entry">
        
        <p>This year I&rsquo;m really looking forward to <a href="http://ubicomp.org">Ubicomp</a> and <a href="http://iswc.net">ISWC</a>,
it&rsquo;s the first time that Ubicomp and Pervasive merged into one conference and it&rsquo;s the first time the venue sold out with 700 participants.</p>
<p>I cannot wait to chat with old friends and experts (most are both :)).</p>
<p>The field slowly matures. Especially, the wearable research is really pushing towards prime-time. Most prominently, Google Glass is getting a lot of focus also discussing its impacts on privacy. Yet, there is more and more talk about fitness bracelets/trackers and smart watches. I expect that we see more intelligent clothes and activity recognition work in commercial products in the coming years.</p>
<p>By the way, we have 3 poster papers and 2 demos at Ubicomp
and a short paper at ISWC.</p>
<p>###Ubicomp Demos and Posters###</p>
<ul>
<li><a href="/papers/kunze2013my.pdf">My Reading Life – Towards Utilizing Eyetracking on Unmodified Tablets and Phones</a></li>
<li><a href="/papers/kunze2013annotate.pdf">Annotate Me – Supporting Active Reading using Real-Time Document Image Retrieval On Mobile Devices</a></li>
<li><a href="/papers/cheng2013activity.pdf">Activity Recognition and Nutrition Monitoring in Every Day Situations with a Textile Capacitive Neckband</a></li>
</ul>
<p>###ISWC paper###</p>
<ul>
<li><a href="/papers/kunze2013know.pdf">I know what you are reading – Recognition of Document Types Using Mobile Eye Tracking</a></li>
</ul>
<p>Drop by at the demo,poster sessions and/or see me my talk on Thursday.</p>
<p>On a side note, Ubicomp really picks great locations. This year it&rsquo;s Zurich, next year Seattle and the year after it will be in Osaka. Seems I might be staying longer in Japan, than I originally planned ;)</p>

        
    </div>

    
    <div class="blog-tags">
        
        <a href="https://kaikunze.de//tags/conference/">conference</a>&nbsp;
        
        <a href="https://kaikunze.de//tags/research/">research</a>&nbsp;
        
        <a href="https://kaikunze.de//tags/ubicomp/">ubicomp</a>&nbsp;
        
        <a href="https://kaikunze.de//tags/iswc/">iswc</a>&nbsp;
        
    </div>
    

</article>
          
            <article class="post-preview">
    <a href="https://kaikunze.de/2013/08/23/recognizing-reading-activities/">
        <h2 class="post-title">Recognizing Reading Activities</h2>
        
        
        
    </a>

    <p class="post-meta">
        <span class="post-meta">
  
  
  <i class="fas fa-calendar"></i>&nbsp;
  
  
    &nbsp;|&nbsp;<i class="fas fa-clock"></i>&nbsp;2&nbsp;minutes
  
  
    &nbsp;|&nbsp;<i class="fas fa-book"></i>&nbsp;326&nbsp;words
  
  
  
</span>


    </p>
    <div class="post-entry">
        
        <script class="speakerdeck-embed" data-id="e9181bd0ee3501308d2a1ad4cad5346c" data-ratio="1.2994923857868" src="//speakerdeck.com/assets/embed.js"> </script>
<p>Just finished my keynote talk at CBDAR (Workshop of <a href="http://icdar2013.org/">ICDAR</a>),
got a lot of questions and have a lot of new research ideas :)</p>
<p>I&rsquo;m pretty ignorant about Document Analysis (and Computer Vision in general), so it&rsquo;s great to talk to some
experts in the field. Pervasive Computing and Document Analysis are very complementary
and as such interesting to combine.</p>
<p>Here are my talk slides, followed by the talk abstract.</p>
<p>##Real-life Activity Recognition - Talk Abstract##</p>
<p>Most applications in intelligent environments so far strongly rely on specific sensor combinations at predefined positions, orientations etc. While this might be acceptable for some application domains (e.g. industry), it hinders the wide adoption of pervasive computing. How can we extract high level information about human actions and complex real world situations from heterogeneous ensembles of simple, often unreliable sensors embedded in commodity devices?</p>
<p>This talk mostly focuses on how to use body-worn devices for activity recognition in general, and how to combine them with infrastructure sensing and computer vision approaches for a specific high level human activity, namely better understanding knowledge acquisition (e.g. recognizing reading activities).</p>
<p>We discuss how placement variations of electronic appliances carried by the user influence the possibility of using sensors integrated in those appliances for human activity recognition. I categorize possible variations into four classes: environmental placements, placement on different body parts (e.g. jacket pocket on the chest, vs. a hip holster vs. the trousers pocket), small displacement within a given coarse location (e.g. device shifting in a pocket), and different orientations.For each of these variations, I give an overview of our efforts to deal with them.</p>
<p>In the second part of the talk, we combine several pervasive sensing approaches (computer vision, motion-based activity recognition etc.) to tackle the problem of recognizing and classifying knowledge acquisition tasks with a special focus on reading. We discuss which sensing modalities can be used for digital and offline reading recognition, as well as how to combine them dynamically.</p>

        
    </div>

    
    <div class="blog-tags">
        
        <a href="https://kaikunze.de//tags/research/">research</a>&nbsp;
        
        <a href="https://kaikunze.de//tags/keynote/">keynote</a>&nbsp;
        
    </div>
    

</article>
          
            <article class="post-preview">
    <a href="https://kaikunze.de/2013/04/29/kai-@-chi/">
        <h2 class="post-title">Kai @ CHI</h2>
        
        
        
    </a>

    <p class="post-meta">
        <span class="post-meta">
  
  
  <i class="fas fa-calendar"></i>&nbsp;
  
  
    &nbsp;|&nbsp;<i class="fas fa-clock"></i>&nbsp;1&nbsp;minutes
  
  
    &nbsp;|&nbsp;<i class="fas fa-book"></i>&nbsp;137&nbsp;words
  
  
  
</span>


    </p>
    <div class="post-entry">
        
        <p>So it&rsquo;s my first time at <a href="http://chi2013.acm.org">CHI</a>. Pretty amazing so far &hellip;
Will blog about more later.</p>
<p><a href="http://kaikunze.de/posters/chiposter2013.pdf"><img src="/posters/tb-chiposter2013.jpg" alt="Chi Poster"></a><img src="/imgs/kai@chi.jpg" alt="Kai@CHI"></p>
<p>I&rsquo;m in the first poster rotation, starting this afternoon:
&ldquo;Towards inferring language expertise using eye tracking&rdquo;
Drop by my poster if you&rsquo;re around (or try to spot me, I&rsquo;m wearing the white &ldquo;Kai@CHI&rdquo; Shirt today :)).</p>
<p>Here&rsquo;s the abstract of our work, as well as the <a href="http://kaikunze.de/papers/kunze2013towards.pdf">link to the paper</a>.</p>
<p>&ldquo;We present initial work towards recognizing reading activities. This paper describes our efforts detect the English skill level of a user and infer which words are difficult for them to understand. We present an initial study of 5 students and show our findings regarding the skill level assessment. We explain a method to spot difficult words. Eye tracking is a promising technology to examine and assess a user’s skill level.&rdquo;</p>

        
    </div>

    
    <div class="blog-tags">
        
        <a href="https://kaikunze.de//tags/chi/">chi</a>&nbsp;
        
        <a href="https://kaikunze.de//tags/research/">research</a>&nbsp;
        
        <a href="https://kaikunze.de//tags/poster/">poster</a>&nbsp;
        
    </div>
    

</article>
          
            <article class="post-preview">
    <a href="https://kaikunze.de/2013/04/24/ar-dagstuhl-report-online/">
        <h2 class="post-title">Activity Recognition Dagstuhl Report Online</h2>
        
        
        
    </a>

    <p class="post-meta">
        <span class="post-meta">
  
  
  <i class="fas fa-calendar"></i>&nbsp;
  
  
    &nbsp;|&nbsp;<i class="fas fa-clock"></i>&nbsp;1&nbsp;minutes
  
  
    &nbsp;|&nbsp;<i class="fas fa-book"></i>&nbsp;166&nbsp;words
  
  
  
</span>


    </p>
    <div class="post-entry">
        
        <p>If you wonder how we spent German tax money, the summary of the
Activity Recognition Dagstuhl seminar is now online.</p>
<p><a href="http://drops.dagstuhl.de/opus/volltexte/2013/3987/">Human Activity Recognition in Smart Environments (Dagstuhl Seminar 12492)</a></p>
<hr>
<p>Here&rsquo;s the abstract:</p>
<p>This report documents the program and the outcomes of Dagstuhl Seminar 12492 &ldquo;Human Activity Recognition in Smart Environments&rdquo;. We established the basis for a scientific community surrounding &ldquo;activity recognition&rdquo; by involving researchers from a broad range of related research fields. 30 academic and industry researchers from US, Europe and Asia participated from diverse fields including pervasive computing, over network analysis and computer vision to human computer interaction. The major results of this Seminar are the creation of a activity recognition repository to share information, code, publications and the start of an activity recognition book aimed to serve as a scientific introduction to the field. In the following, we go into more detail about the structure of the seminar, discuss the major outcomes and give an overview about discussions and talks given during the seminar.</p>

        
    </div>

    
    <div class="blog-tags">
        
        <a href="https://kaikunze.de//tags/dagstuhl/">dagstuhl</a>&nbsp;
        
        <a href="https://kaikunze.de//tags/research/">research</a>&nbsp;
        
    </div>
    

</article>
          
        </div>
        
      </div>
    </div>
  </div>

      
<footer>
  <div class="container">
    <div class="row">
      <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
        <ul class="list-inline text-center footer-links">
          
          
          <li>
            <a href="/tags/research/index.xml" title="RSS">
              <span class="fa-stack fa-lg">
                <i class="fas fa-circle fa-stack-2x"></i>
                <i class="fas fa-rss fa-stack-1x fa-inverse"></i>
              </span>
            </a>
          </li>
          
        </ul>
        <p class="credits copyright text-muted">
          

          &nbsp;&bull;&nbsp;&copy;
          
            2024
          

          
            &nbsp;&bull;&nbsp;
            <a href="https://kaikunze.de/">Kai Kunze</a>
          
      </div>
    </div>
  </div>
</footer><script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.js" integrity="sha384-K3vbOmF2BtaVai+Qk37uypf7VrgBubhQreNQe9aGsz9lB63dIFiQVlJbr92dw2Lx" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/contrib/auto-render.min.js" integrity="sha384-kmZOZB5ObwgQnS/DuDg6TScgOiWWBiVt0plIRkZCmE6rDZGrEOQeHM5PcHi+nyqe" crossorigin="anonymous"></script>
<script   src="https://code.jquery.com/jquery-3.7.0.min.js"  integrity="sha256-2Pmvv0kuTBOenSvLm6bvfBSSHrUJ+3A7x6P5Ebd07/g="   crossorigin="anonymous"></script>
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>

<script src="https://kaikunze.de/js/main.js"></script>
<script src="https://kaikunze.de/js/highlight.min.js"></script>
<script> hljs.initHighlightingOnLoad(); </script>
<script> $(document).ready(function() {$("pre.chroma").css("padding","0");}); </script><script> renderMathInElement(document.body); </script><script src="https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/photoswipe.min.js" integrity="sha384-QELNnmcmU8IR9ZAykt67vGr9/rZJdHbiWi64V88fCPaOohUlHCqUD/unNN0BXSqy" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/photoswipe-ui-default.min.js" integrity="sha384-m67o7SkQ1ALzKZIFh4CiTA8tmadaujiTa9Vu+nqPSwDOqHrDmxLezTdFln8077+q" crossorigin="anonymous"></script><script src="https://kaikunze.de/js/load-photoswipe.js"></script>







    
  </body>
</html>

