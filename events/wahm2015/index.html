<!DOCTYPE html>
<html lang="en">

<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <meta name="author" content="">

    <title>Creative - Start Bootstrap Theme</title>

    <!-- Bootstrap Core CSS -->
    <link rel="stylesheet" href="css/bootstrap.min.css" type="text/css">

    <!-- Custom Fonts -->
    <link href='http://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800' rel='stylesheet' type='text/css'>
    <link href='http://fonts.googleapis.com/css?family=Merriweather:400,300,300italic,400italic,700,700italic,900,900italic' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" href="font-awesome/css/font-awesome.min.css" type="text/css">

    <!-- Plugin CSS -->
    <link rel="stylesheet" href="css/animate.min.css" type="text/css">

    <!-- Custom CSS -->
    <link rel="stylesheet" href="css/creative.css" type="text/css">

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

</head>

<body id="page-top">

    <nav id="mainNav" class="navbar navbar-default navbar-fixed-top">
        <div class="container-fluid">
            <!-- Brand and toggle get grouped for better mobile display -->
            <div class="navbar-header">
                <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
                    <span class="sr-only">Toggle navigation</span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>
                <a class="navbar-brand page-scroll" href="#page-top">WAHM 2015</a>
            </div>

            <!-- Collect the nav links, forms, and other content for toggling -->
            <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
                <ul class="nav navbar-nav navbar-right">
                    <li>
                        <a class="page-scroll" href="#about">Abstract</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#services">Call For Participation</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#format">Submission Format</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#portfolio">Schedule</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#contact">Organizers</a>
                    </li>
                </ul>
            </div>
            <!-- /.navbar-collapse -->
        </div>
        <!-- /.container-fluid -->
    </nav>

    <header>
        <div class="header-content">
            <div class="header-content-inner text-left">
                <h1>2nd UbiComp Workshop on Ubiquitous Technologies to Augment the Human Mind </h1>
                <hr>
            </div>
        </div>
    </header>

    <section class="bg-primary" id="about">
        <div class="container">
            <div class="row">
                <div class="col-lg-8 col-lg-offset-2 text-left">

                    <p class="primary"> The Workshop on Ubiquitous Technologies for Augmenting the Human Mind (WAHM) will be held on September 8th at Ubicomp 2015 in Osaka.<p>

<p class="primary"> Workshop submission deadline: July 3, 2015 <p>
                            <p class="primary"> Feedback to authors: July 10, 2015 <p>
                                    <p class="primary">  Camera-ready version: July 15 2015 (hard deadline) <p>
                                        <p class="primary"> Workshop at Ubicomp 2015: September 7/8, 2015 <p>
                                        
                                                <p class="primary">All submissions should be sent as PDF to wahm2015@hcilab.org with "WAHM 2015 Submission" as email subject. See below for formating details.</p>

                    <h2 class="section-heading">Toward the Knowledge Log</h2>
                    <p class="primary">Lifelogging technologies, the use of sensing technologies to analyze and record one’s lives, is on the rise. Products from industry and research in academia currently focus on using the collected data to support health and fitness. Given these trends, it is only a matter of time before we see mobile sens- ing technology applied to cognitive tasks, enabling novel research directions and use cases. In this workshop, we explore the implications of ”knowledge logging”, how to record and track what we read, learn, comprehend and how this impacts research towards mind augmentation. The goal of this workshop is to combine innovations in ubiquitous computing with basic research in psychology and cognitive science. The aim is to bring mind augmentation technologies from a niche application in rehabilitation to a mainstream technology and initiating a major change in the way we use technology to externalize our mind. This workshop will bring together researchers, designers and practitioners at the intersection of technology and cognitive psychology to discuss elements and viewpoints of knowledge logging, inferring cognitive states and extending our perception.<p>
                </div>
            </div>
        </div>
    </section>

    <section id="services">
    <div class="container">
            <div class="row">
                <div class="col-lg-8 col-lg-offset-2 text-left">
                    <h2 class="section-heading">Call for Participation</h2>
                    <p>To approach the challenges of augmenting the human mind, we will focus on the following themes, depending on participants’ contributions:<p>
                        Sensing Technologies: How do signals gathered from ubiquitous sensing devices relate to cognitive processes? Defining sensing and interaction modalities to better understand human behavior.<p>
Applied cognitive theories: How can we use these real life recordings of physical, physiological and cognitive signals to augment our mind and, for example, induce wanted long-term behavior change for users?
<p>
Building ”knowledge logs”: From an information retrieval and processing perspective we want to discuss potential technologies relevant for cognitive processing. Personal “knowledge logs” can be can be compiled from sensing using adaptive algorithms automated daily summaries.<p>

HCI to extend the mind: we are looking for Innovative User Interfaces for mind augmentation, including technologies for information priming. For example, how can feedback through ambient large displays and personal mobile devices aid personal knowledge acquisition, retention, and attenuation?<p>

Commercial application areas for human mind augmentation: While many of the application domains for such technologies are for the public good, the same technologies can also be employed in the commercial context. For example, technology could be used to augment meetings detecting the comprehension of each participant and help mitigate potential misunderstandings.<p>
Discussing privacy security and social implications.<p>

The goals of the WAHM 2015 workshop picks up on last year’s theme: we want to foster discussions about technologies that nurture the augmentation of the human mind. Given the good reception of the first workshop and the feedback that we should include a broader range of topics (last year focused on memory), we are working on extending our community. The above-mentioned themes will be used as a starting point for the discussion and group analysis (described below). However, we will also pay attention to new themes possibly emerging from morning presentation and discussions. In addition to shaping the research agenda, we will also dis- cuss social impact and potential commercial applications. To this end we will also invite representatives from corporate re- search.

                </div>
            </div>
        </div>


    </section>

    <section class="bg-primary" id="format">
        <div class="container">
            <div class="row">
                <div class="col-lg-8 col-lg-offset-2 text-left">
                    <h2 class="section-heading">Submission Format</h2>
                    <p class="primary">
Workshop candidates are requested to send a position paper (4-8 pages in the <u><a href="http://www.sigchi.org/publications/chipubform/sigchi-extended-abstracts-format-2016/view"; color: orange;> ACM SIGCHI non- archival Extended Abstracts word template </a></u> or <u><a href="https://github.com/sigchi/Document-Formats"> Latex template</a></u> (landscape format)) to the organizers about their research and link to the workshop theme. In addition to describing their work candidates will be asked to write about challenges and opportunities they see for technology that augments the human mind, in order to prepare the candidates the workshop theme. Participants will be selected on the basis of the relevance of their work and interests and familiarity with the WAHM workshop topics. Accepted submissions will be included in the UbiComp 2015 Adjunct Proceedings and listed in the ACM Digital Library.

All submissions should be sent as PDF to wahm2015@hcilab.org with "WAHM 2015 Submission" as email subject.<p>
                </div>
            </div>
        </div>
    </section>

    <section id="contact">
        <div class="container">
            <div class="row">
                <div class="col-lg-8 col-lg-offset-2 text-left">
                    <h2 class="section-heading">Organizers</h2>
                    <h3 class="section-heading">Kai Kunze</h3>
                    <p class="primary">Kai Kunze works as an associate project professor at Keio Media Design, Keio University. Beforehand, he held an assistant professorship at Osaka Prefecture Uni- versity. He received a Summa Cum Laude for his phD thesis, University Passau. He was visting researcher at the MIT Media Lab. His work experience includes internships at the Palo Alto Research Center (PARC), Sunlabs Europe and the Research Department of the German Stock Exchange. His major research contributions are in pervasive computing, es- pecially in sensing, physical and cognitive activity recognition. Recently, he focuses on tracking knowledge acquisition activities, especially reading.<p>
                    <h3 class="section-heading">Tilman Dingler</h3>
                    <p class="primary">
Tilman Dingler is a researcher at the Institute for Visualization and Interactive Systems at University of Stuttgart. He focuses on concepts and applications in the field of Pervasive Computing, thereby developing embedded devices and software for context-aware systems that put users and their context at the center. Tilman holds a Diploma in Media Computer Science from the University of Munich, a Master’s degree in Web Science from the University of San Francisco and an Honors degree in Technology Management from the Center for Digital Technology and Management in Munich. Before starting his PhD, Tilman was developing software for TinyCo and Yahoo!.<p>
                    <h3 class="section-heading">Niels Henze</h3>
                    <p class="primary">is assistant professor for Socio-Cognitive Systems in the Institute for Visualization and Interactive Systems and the SimTech Cluster for Simulation Technology at the University of Stuttgart. He received awards from different
conferences including CHI and MobileHCI. He is interested in large-scale human subject studies, improvement of inter- active systems through models of human behavior, and smart attention management.<p>
                    <h3 class="section-heading">Koichi Kise</h3>
                    <p class="primary">
is a professor in the Department of Computer Science and Intelligent Systems at Osaka Prefecture Univer- sity. From 2000 to 2001, he was a visiting professor at Ger- man Research Center for Artificial Intelligence (DFKI), Ger- many. He received awards including the best paper award of IEICE in 2008, the IAPR/ICDAR best paper awards in 2007 and 2013, the IAPR Nakano award in 2010, the ICFHR best paper award in 2010 and the ACPR best paper award in 2011. He works as the chair of the IAPR technical committee 11 (reading systems) and a member of the IAPR conferences and meetings committee. His major research activities are in analysis, recognition and retrieval of documents, images and activities.
                        <p>
                    <h3 class="section-heading">Yoichi Sato</h3>
                    <p class="primary">
                        is a professor at the Institute of Industrial Science, the University of Tokyo, jointly affiliated with the Graduate School of Interdisciplinary Information Studies and Graduate School of Information Science and Technology. He received the BSE degree from the University of Tokyo in 1990, and the MS and PhD degrees in robotics from the School of Computer
Science, Carnegie Mellon University, Pittsburgh, Pennsylvania, in 1993 and 1997 respectively.<p>
                </div>
            </div>
        </div>

    </section>

    <!-- jQuery -->
    <script src="js/jquery.js"></script>

    <!-- Bootstrap Core JavaScript -->
    <script src="js/bootstrap.min.js"></script>

    <!-- Plugin JavaScript -->
    <script src="js/jquery.easing.min.js"></script>
    <script src="js/jquery.fittext.js"></script>
    <script src="js/wow.min.js"></script>

    <!-- Custom Theme JavaScript -->
    <script src="js/creative.js"></script>

</body>

</html>
