<!DOCTYPE html>
<html>
<head>
  <title>Towards Dynamically Configurable Context Recognition Systems</title>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="">
    <meta name="author" content="">
    
    <link href="/css/bootstrap.min.css" rel="stylesheet">
    
    <link href="/css/blog.css" rel="stylesheet">
    <link rel="stylesheet" href="/css/font-awesome.min.css">

  </head>

      <div class="blog-masthead">
      <div class="container">
        <nav class="nav">
          
          <a class="nav-link" href=/> Kai </a>
          
          <a class="nav-link" href=/post/> blog </a>
          
          <a class="nav-link" href=/research/> research </a>
          
          <a class="nav-link" href=/contact/> contact </a>
          
        </nav>
      </div>
    </div>
    <body>

<div class="container">
  <div class="row">
  <div class="col-sm-9">
  <div class="blog-post">
            <h2 class="blog-post-title"> Towards Dynamically Configurable Context Recognition Systems</h2>
 <p class="blog-post-meta">Mon, Jul 9, 2012</p>
  <p>Here&rsquo;s a <a href="http://kaikunze.de/papers/2012Kunze.pdf">draft version of my publication</a> for the <a href="http://activitycontext.org/">Activity Context Workshop</a>
in Toronto. Bellow the abstract.</p>

<p>Here&rsquo;s the link to the <a href="https://github.com/kkai/snsrlog">source code for snsrlog for iPhone</a> (which I mentioned during my talk).</p>

<hr />

<p>Abstract</p>

<p>General representation, abstraction and exchange definitions are crucial for dynamically configurable context recognition.
However, to evaluate potential definitions, suitable standard datasets are needed.
This paper presents our effort to create and maintain large scale, multimodal standard datasets
for context recognition research. We ourselves used these datasets in previous research to deal with placement effects
and presented low-level sensor abstractions in motion based on-body sensing.
Researchers, conducting novel data collections, can rely on the toolchain and the the low-level sensor
abstractions summarized in this paper. Additionally, they can draw from our experiences developing and
conducting context recognition experiments.
Our toolchain is already a valuable rapid prototyping tool. Still, we plan to extend it to crowd-based
sensing, enabling the general public to gather context data, learn more about their lives and contribute
to context recognition research.
Applying higher level context reasoning on the gathered context data is a obvious extension to our work.</p>

</div>
</div>
</div>
</div>
</br>
<footer class="blog-footer">
  <p> built by Kai, 2017. </p>
  <p>
    <a href="#">Back to top</a>
  </p>
</footer>
</body>
<script type="text/javascript">
    var GoSquared = {};
    GoSquared.acct = "GSN-181843-L";
     (function(w){
    function gs(){
      w._gstc_lt = +new Date;
      var d = document, g = d.createElement("script");
      g.type = "text/javascript";
      g.src = "//d1l6p2sc9645hc.cloudfront.net/tracker.js";
      var s = d.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(g, s);
    }
    w.addEventListener ?
      w.addEventListener("load", gs, false) :
      w.attachEvent("onload", gs);
    })(window);
</script>
</html>

